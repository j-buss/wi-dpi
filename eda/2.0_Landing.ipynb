{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "wi-dpi-all-staff-eda.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/j-buss/wi-dpi-analysis/blob/development/eda/2.0_Landing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYnVbPCC1u1b",
        "colab_type": "text"
      },
      "source": [
        "# Salary and Education in Wisconsin - 2.0 Load Landing BigQuery"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JixlqF171iMF",
        "colab_type": "text"
      },
      "source": [
        "This notebook is intended to describe analysis on salaries of teachers within the Wisconsin Department of Public Instruction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E770jioT8RX-",
        "colab_type": "text"
      },
      "source": [
        "## Introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhwK8pzspUrA",
        "colab_type": "text"
      },
      "source": [
        "### Load libraries\n",
        "Install the following packages in order to load data to BigQuery.\n",
        "\n",
        "*Please note this will require a restart to the runtime*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtGtyuBxjjWM",
        "colab_type": "code",
        "outputId": "860cb510-c966-43cd-8822-c0e5e267fc02",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1684
        }
      },
      "source": [
        "!pip install --upgrade google-cloud-bigquery\n",
        "!pip install gcsfs\n",
        "!pip install pandas-gbq -U"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting google-cloud-bigquery\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/c1/74dce5b9ffde50910082431e9117e221f18978efec88a085e3ec46d63ed4/google_cloud_bigquery-1.12.1-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.9MB/s \n",
            "\u001b[?25hCollecting google-cloud-core<2.0dev,>=1.0.0 (from google-cloud-bigquery)\n",
            "  Downloading https://files.pythonhosted.org/packages/34/ba/251d9b6a1695d25d9f081a3db537b0dfb15edaf2037b423e4a98280df7f9/google_cloud_core-1.0.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->google-cloud-bigquery) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.0->google-cloud-bigquery) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (1.5.10)\n",
            "Requirement already satisfied, skipping upgrade: pytz in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2019.3.9)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery) (0.4.5)\n",
            "\u001b[31mERROR: google-cloud-translate 1.3.3 has requirement google-cloud-core<0.30dev,>=0.29.0, but you'll have google-cloud-core 1.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: google-cloud-storage 1.13.2 has requirement google-cloud-core<0.30dev,>=0.29.0, but you'll have google-cloud-core 1.0.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: google-cloud-core, google-cloud-bigquery\n",
            "  Found existing installation: google-cloud-core 0.29.1\n",
            "    Uninstalling google-cloud-core-0.29.1:\n",
            "      Successfully uninstalled google-cloud-core-0.29.1\n",
            "  Found existing installation: google-cloud-bigquery 1.8.1\n",
            "    Uninstalling google-cloud-bigquery-1.8.1:\n",
            "      Successfully uninstalled google-cloud-bigquery-1.8.1\n",
            "Successfully installed google-cloud-bigquery-1.12.1 google-cloud-core-1.0.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting gcsfs\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/19/68ab4e6570a7882698058be8ecf1b195b0b784b838ac1b0ea82c422c0f5a/gcsfs-0.2.2.tar.gz (52kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 2.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.6/dist-packages (from gcsfs) (1.4.2)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from gcsfs) (0.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from gcsfs) (2.21.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from gcsfs) (4.4.0)\n",
            "Requirement already satisfied: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (3.1.0)\n",
            "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (4.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (1.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth>=1.2->gcsfs) (0.2.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->gcsfs) (1.2.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2019.3.9)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->gcsfs) (2.8)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa>=3.1.4->google-auth>=1.2->gcsfs) (0.4.5)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs) (3.0.1)\n",
            "Building wheels for collected packages: gcsfs\n",
            "  Building wheel for gcsfs (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Stored in directory: /root/.cache/pip/wheels/9f/0f/b9/5bc5222756d121ccace51ab3084a1c733380908a4e2f939038\n",
            "Successfully built gcsfs\n",
            "Installing collected packages: gcsfs\n",
            "Successfully installed gcsfs-0.2.2\n",
            "Collecting pandas-gbq\n",
            "  Downloading https://files.pythonhosted.org/packages/6a/65/bc46678a5550c0cef1700d7292319deae716751af3f6158250d6a3a454ed/pandas_gbq-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: google-auth-oauthlib in /usr/local/lib/python3.6/dist-packages (from pandas-gbq) (0.3.0)\n",
            "Collecting pydata-google-auth (from pandas-gbq)\n",
            "  Downloading https://files.pythonhosted.org/packages/89/c5/03b68c114bc2c2bcaa2e40fdf269a14361fa75b70a09415e8bad65413b75/pydata_google_auth-0.1.3-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from pandas-gbq) (41.0.1)\n",
            "Requirement already satisfied, skipping upgrade: google-auth in /usr/local/lib/python3.6/dist-packages (from pandas-gbq) (1.4.2)\n",
            "Requirement already satisfied, skipping upgrade: pandas>=0.19.0 in /usr/local/lib/python3.6/dist-packages (from pandas-gbq) (0.24.2)\n",
            "Requirement already satisfied, skipping upgrade: google-cloud-bigquery>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from pandas-gbq) (1.12.1)\n",
            "Requirement already satisfied, skipping upgrade: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib->pandas-gbq) (1.2.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth->pandas-gbq) (0.2.5)\n",
            "Requirement already satisfied, skipping upgrade: cachetools>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth->pandas-gbq) (3.1.0)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from google-auth->pandas-gbq) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth->pandas-gbq) (4.0)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas-gbq) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas-gbq) (1.16.3)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.19.0->pandas-gbq) (2.5.3)\n",
            "Requirement already satisfied, skipping upgrade: google-api-core<2.0.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=1.9.0->pandas-gbq) (1.11.0)\n",
            "Requirement already satisfied, skipping upgrade: google-resumable-media>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=1.9.0->pandas-gbq) (0.3.2)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=1.9.0->pandas-gbq) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: google-cloud-core<2.0dev,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=1.9.0->pandas-gbq) (1.0.0)\n",
            "Requirement already satisfied, skipping upgrade: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq) (3.0.1)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq) (2.21.0)\n",
            "Requirement already satisfied, skipping upgrade: pyasn1<0.5.0,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth->pandas-gbq) (0.4.5)\n",
            "Requirement already satisfied, skipping upgrade: googleapis-common-protos!=1.5.4,<2.0dev,>=1.5.3 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0dev,>=1.6.0->google-cloud-bigquery>=1.9.0->pandas-gbq) (1.5.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq) (2.8)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq) (2019.3.9)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.0.0->requests-oauthlib>=0.7.0->google-auth-oauthlib->pandas-gbq) (3.0.4)\n",
            "Installing collected packages: pydata-google-auth, pandas-gbq\n",
            "  Found existing installation: pandas-gbq 0.4.1\n",
            "    Uninstalling pandas-gbq-0.4.1:\n",
            "      Successfully uninstalled pandas-gbq-0.4.1\n",
            "Successfully installed pandas-gbq-0.10.0 pydata-google-auth-0.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPuM0yyTed1Q",
        "colab_type": "text"
      },
      "source": [
        "### Authenticate to Google Cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYIG0s-0ec9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q0v-JSvaAiqM",
        "colab_type": "text"
      },
      "source": [
        "### Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cyEpDjO19Tt1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_columns', 50)\n",
        "pd.set_option('display.max_rows', 5)\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZufn9GG9W5q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "plt.style.use('bmh')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzBusRztAnPi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.cloud import bigquery\n",
        "from google.cloud import storage\n",
        "from io import StringIO\n",
        "import re\n",
        "import collections"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfqK__FMONeR",
        "colab_type": "text"
      },
      "source": [
        "### Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ioY3_FupCJ8b",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def download_file(url, filename):\n",
        "  r = requests.get(url)\n",
        "  f = open(filename,'wb')\n",
        "  f.write(r.content)\n",
        "  f.close()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAvU_MEyOJ4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_dataset(client, project_id, dataset_name):\n",
        "  \n",
        "  \n",
        "  dataset_id = \"{}.{}\".format(project_id, dataset_name)\n",
        "  dataset = bigquery.Dataset(dataset_id)\n",
        "  dataset.location = \"US\"\n",
        "\n",
        "  dataset = client.create_dataset(dataset)\n",
        "  #print(\"Created dataset {}.{}\".format(client.project, dataset.dataset_id))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOMI9QWsby8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def delete_dataset(client, project_id, dataset_name):\n",
        "  \n",
        "  \n",
        "  dataset_id = \"{}.{}\".format(project_id, dataset_name)\n",
        "  client.delete_dataset(dataset_id, delete_contents=True, not_found_ok=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wKFdTT1-Nbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_blob_list(project_id, bucket_name):\n",
        "    \"\"\"Lists all the blobs in the bucket.\"\"\"\n",
        "    storage_client = storage.Client(project=project_id)\n",
        "    bucket = storage_client.get_bucket(bucket_name)\n",
        "\n",
        "    blobs = bucket.list_blobs()\n",
        "    return blobs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "61YoyFbkWzI9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def clean_column_headers(columns):\n",
        "  return columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '').str.replace('.','_').str.replace('/','_').str.replace(\"'\",\"\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4lJBE_QB8gqh",
        "colab_type": "text"
      },
      "source": [
        "### Define Values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ge6tOEad9OSK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "project_id='wi-dpi-010'\n",
        "raw_data_bucket_name='landing-009'\n",
        "\n",
        "landing_dataset_name='landing'\n",
        "refined_dataset_name='refined'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIzr1UNerQWw",
        "colab_type": "text"
      },
      "source": [
        "## Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QGPBL6pB8uz7",
        "colab_type": "text"
      },
      "source": [
        "### Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fAl_QS--cS_F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "landing_dataset_name = 'landing'\n",
        "bq_client = bigquery.Client(project=project_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0P1MbpYg36z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "create_dataset(bq_client, project_id, landing_dataset_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFP_lDI6bVPA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###DELETE DATASET\n",
        "delete_dataset(bq_client, project_id, landing_dataset_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fug36iW38yti",
        "colab_type": "text"
      },
      "source": [
        "### Create Dataframes and Tables from GCS Blobs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzrS1imIA7tK",
        "colab_type": "text"
      },
      "source": [
        "For all files (blobs) in the bucket we will split the blob name into the following components:\n",
        "\n",
        "\n",
        "1.   Source\n",
        "2.   Year\n",
        "3.   File\n",
        "4.   File Type\n",
        "\n",
        "Additionally, we will use a NamedTuple to define the components and ensure they are callable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y079XL3UC6cS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "blob_to_process = collections.namedtuple('blob_to_process','source year file file_type fullname')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q3hTOUYG8p4M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list_of_blobs = []\n",
        "for blob in return_blob_list('wi-dpi-010','landing-009'):\n",
        "  temp = re.findall(r\"[\\w']+\",blob.name)\n",
        "  temp.append(blob.name)\n",
        "  if len(temp) == 5:\n",
        "    list_of_blobs.append(blob_to_process(*temp))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jEK0D5F_2F5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TEMPORARY REPROCESS\n",
        "#list_of_blobs = [blob_to_process(source='all_staff_report', year='2015', file='2015_assignment_area', file_type='csv', fullname='all_staff_report/2015/2015_assignment_area.csv')]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd9UJczY43W3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "8c3acccf-9282-4d35-c052-64b83e2676e9"
      },
      "source": [
        "print(list_of_blobs)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[blob_to_process(source='all_staff_report', year='2015', file='2015_assignment_area', file_type='csv', fullname='all_staff_report/2015/2015_assignment_area.csv')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J53WGstUPxXL",
        "colab_type": "text"
      },
      "source": [
        "Now the object \n",
        "`list_of_blobs`\n",
        "has all the blob object information. We will cycle through it to create the tables as needed in BigQuery."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwuL9NrlSJKV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "storage_client = storage.Client(project=project_id)\n",
        "bucket = storage_client.get_bucket(raw_data_bucket_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV7MMYTCN8-l",
        "colab_type": "code",
        "outputId": "6aed2f75-2961-4ad3-a195-39ebf587c787",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "for blob in list_of_blobs:\n",
        "  if blob.file_type == 'csv':\n",
        "    data_blob = bucket.get_blob(blob.fullname)\n",
        "    data = data_blob.download_as_string()\n",
        "    df = pd.read_csv(StringIO(data.decode('utf-8')),low_memory=False)\n",
        "    df.columns = clean_column_headers(df.columns)\n",
        "    print (landing_dataset_name + '.' + blob.file)\n",
        "    df.to_gbq(landing_dataset_name + '.' + blob.file,project_id=project_id,if_exists='replace')\n",
        "  elif blob.file_type == 'fwf':\n",
        "    data_blob = bucket.get_blob(blob.fullname)\n",
        "    data = data_blob.download_as_string()\n",
        "    metadata_file = [x_blob.source + '/' + x_blob.year + '/' + x_blob.file + '.' + x_blob.file_type for x_blob in list_of_blobs\\\n",
        "           if (x_blob.file == blob.file and x_blob.file_type != blob.file_type)][0]\n",
        "    metadata_blob = bucket.get_blob(metadata_file)\n",
        "    metadata = metadata_blob.download_as_string()\n",
        "    metadata_df = pd.read_csv(StringIO(metadata.decode('utf-8')))\n",
        "    col_widths = metadata_df['length'].apply(int)\n",
        "    col_names = metadata_df['name']\n",
        "    df = pd.read_fwf(StringIO(data.decode('utf-8')), widths=col_widths, names=col_names)\n",
        "    df.columns = clean_column_headers(df.columns)\n",
        "    print (landing_dataset_name + '.' + blob.file)\n",
        "    df.to_gbq(landing_dataset_name + '.' + blob.file,project_id=project_id,if_exists='replace')\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "landing.2015_assignment_area\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "1it [00:03,  3.17s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4CRP9H8sdX8E",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}